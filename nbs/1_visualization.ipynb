{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb7c7f6",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python </p></td>\n",
    "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab150ad",
   "metadata": {},
   "source": [
    "# Part 1: Image and its visualisation\n",
    "\n",
    "The course aims to introduce you to the essential knowledge to image processing and analysis of microscopic data in Python. \n",
    "\n",
    "In this part 1 of the course, we hope the course attendees will be able to:\n",
    "- run a Python notebook\n",
    "- get familiar with relevant Python packages\n",
    "- load and read microscopic images and metadata using the package bioio\n",
    "- understand what an image is\n",
    "- visualise different channel or section of an image using the matplotlib library\n",
    "- visualise different channel or section of an image using the napari plugin\n",
    "- visualise moving particles and their trajectories in napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86064ef3",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "\n",
    "Let us first download some data while looking at how to load a package. A package contains functions or modules that are ready to use. \n",
    "\n",
    "<font color=\"red\">To-do: Correct the link to download</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be261cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "def download_and_unzip(url, extract_to='.'):\n",
    "    http_response = urlopen(url)\n",
    "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "    zipfile.extractall(path=extract_to)\n",
    "\n",
    "url = 'https://cloud.mrc-lmb.cam.ac.uk/s/AegYyMp3ajfaZME/download/data.zip'\n",
    "data_folder = Path('./data')\n",
    "download_and_unzip(url, data_folder)\n",
    "\n",
    "print(f'List of files in the {data_folder} folder')\n",
    "for x in (data_folder).glob('*'):\n",
    "    print(f' {str(x.name)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa0f7a",
   "metadata": {},
   "source": [
    "### Load data using bioio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ec873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "from pathlib import Path\n",
    "\n",
    "data_folder = r\"Y:\\Courses\\Given\\Python course\\data\"\n",
    "image = BioImage(Path(data_folder, 'airyscan-4colors.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67418e",
   "metadata": {},
   "source": [
    "<font color=\"red\">!ERROR</font>\n",
    "\n",
    "bioio now works after re-installing the environment and pip install bioio-tifffile\n",
    "which seems to be extra work instead of just using import tifffile :<\n",
    "\n",
    "The error is as follows:\n",
    "\n",
    "<font color=\"red\">\n",
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "ome-zarr 0.11.1 requires zarr<3,>=2.8.1, but you have zarr 3.1.2 which is incompatible.\n",
    "ome-zarr-models 0.1.10 requires zarr<3, but you have zarr 3.1.2 which is incompatible.\n",
    "pydantic-zarr 0.7.0 requires zarr<3.0.0,>=2.14.2, but you have zarr 3.1.2 which is incompatible.\n",
    "</font>\n",
    "\n",
    "<font color=\"red\">-- end error --</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98b110",
   "metadata": {},
   "source": [
    "The image and its metadata are now loaded into the variable \"image\". Next, we read the image and the metadata. \n",
    "\n",
    "### Metadata\n",
    "\n",
    "Metadata stores information describing the data. It includes the number of channels in the images, the name of each channel and emission wavelength associated with each channel, the voxel size, and many other acquisition parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.data\n",
    "image.metadata\n",
    "image.physical_pixel_sizes\n",
    "image.shape\n",
    "image.dims\n",
    "image.channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba27721",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise \n",
    "\n",
    "In the next cell, get familiar with the contents of the variable \"image\" and the metadata by printing the values stored in it one by one and understand the outputs. \n",
    "    \n",
    "Hint: use the function print()\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62da543e",
   "metadata": {},
   "source": [
    "### Image dimension and pixel sizes\n",
    "\n",
    "Next, we will check the different dimensions of our image. To illustrate this, we need to know what a dictionnary is as it is required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a004e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim, element in enumerate(image.dims.order):\n",
    "    print(f'Array axis {dim} is {element} with size {image.dims[element][0]}')\n",
    "\n",
    "print(f'The name of the channels are {image.channel_names}')\n",
    "print(f'The pixel size in X is {image.physical_pixel_sizes}')\n",
    "print(f'The pixel size in X is {image.physical_pixel_sizes.X:.4f} microns')\n",
    "print(f'The pixel size in Y is {image.physical_pixel_sizes.Y:.4f} microns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029983b",
   "metadata": {},
   "source": [
    "### What is an image?\n",
    "\n",
    "A digital image is a finite numeric representation of the intensity values. It is composed of picture elements known as pixels. \n",
    "\n",
    "In Python, it can be manipulated as a N-dimensional array using the class numpy.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the numpy package used for manipulating images\n",
    "import numpy as np\n",
    "\n",
    "# get the array of pixels intensity as a numpy object\n",
    "data = image.data\n",
    "\n",
    "# Print the type of the array\n",
    "print('The data is a ', type(data)) \n",
    "\n",
    "# Print the dimension of the array\n",
    "print('The array has the following shape', data.shape) \n",
    "\n",
    "# Print the physical pixel sizes and the types\n",
    "pixel = image.physical_pixel_sizes\n",
    "print('The physical pixel sizes are', pixel)\n",
    "print('The pixel type is a', type(pixel)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec54cef",
   "metadata": {},
   "source": [
    "Let us now display an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c79a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib for loading images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's display the second channel as a 2D image in a figure\n",
    "plt.imshow(data[0,1,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2900433",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "\n",
    "Display the second and third channels in the image and change the colormap cmap value to 'hot'.\n",
    "    \n",
    "Hint: use the same function that in the previous cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac26b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38a18d2b",
   "metadata": {},
   "source": [
    "Now let's display all the channels of the image in a subplot using a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute the number of channels\n",
    "num_channels = image.shape[1]\n",
    "\n",
    "# Display the image for each channel\n",
    "fig, ax = plt.subplots(1, num_channels, figsize=(16,4))\n",
    "for k  in range(num_channels):    \n",
    "    ax[k].imshow(image.data[0,k,0], cmap='hot')\n",
    "    ax[k].set_axis_off()\n",
    "    ax[k].set_title(image.channel_names[k])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5394c62",
   "metadata": {},
   "source": [
    "In the following cell, we crop a part of the image, display it in a figure and overlay the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop and downsample the array by a factor of 5\n",
    "crop = image.data[0, 0, 0, 850:950:5, 900:1000:5] \n",
    "\n",
    "# Create a figure with axes\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Display the downsampled array in the figure\n",
    "plt.imshow(crop, cmap='gray')\n",
    "\n",
    "# Add the values of the pixel intensity\n",
    "for i in range(crop.shape[0]):\n",
    "    for j in range(crop.shape[1]):\n",
    "        c = 'white' if crop[i, j] < 5 else 'black'\n",
    "        ax.text(j, i, str(int(crop[i, j])), color=c, ha='center', va='center', size=10)\n",
    "ax.axis(\"off\")\n",
    "plt.title('Pixel values');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7975ef4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "    \n",
    "Modify the previous cell to\n",
    "\n",
    "1. select a different region within the image and display an overlay of the image with the pixel values,\n",
    "2. check again the size of the image to be sure of not going out of bounds,\n",
    "3. choose an appropriate downsampling factor,\n",
    "4. adjust the figsize for a proper and visible display if necessary.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f687b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee1ab6f",
   "metadata": {},
   "source": [
    "## Napari plugin\n",
    "\n",
    "Napari is a fast, interactive, and open-source Python tool for viewing, annotating, and analyzing large multi-dimensional scientific images. It allows users to visualize 2D, 3D, and higher-dimensional data on a single canvas, overlay derived data like points and segmentations, and seamlessly integrate exploration with computation and annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(data, channel_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b7dff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "    \n",
    "Create a napari viewer to display the airyscan-4colors.tif data. Display the name of the channels and set the contrast limits as the minimal and maximal values.\n",
    "\n",
    "1. set the `name` variable to be the image.channel_names or an user-defined list of channels names,\n",
    "2. create a list of min and max intensity value for the 4 channels,\n",
    "3. set the `contrast_limits` of each channel to range between the min and max intensity by attributing the `contrast_limits` variable to the created list in step 2,\n",
    "\n",
    "Hint: use np.min(data[:, n, :, :, :]) and np.max(data[:, n, :, :, :]) to find the min and max of the n-th channel respectively\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "contrast_limits = [[np.min(data[:, n, :, :, :]), np.max(data[:, n, :, :, :])] for n in np.arange(data.shape[1])]\n",
    "contrast_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb722f0",
   "metadata": {},
   "source": [
    "We can also display timelapse data, points and tracks with napari. To do this, we will use the pandas library to first read the trajectories stored in an excel data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "from pathlib import Path\n",
    "\n",
    "file = \"170725_Sun Bicd2_1hr_no delay_SRNA_1008.nd2\"\n",
    "filedir = Path(data_folder, file)\n",
    "\n",
    "image = BioImage(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "image = BioImage(filedir)\n",
    "data  = image.data[0:200, :, :, 280:360, 410:490]\n",
    "tracks = pd.read_excel(Path(data_folder, \"result_lt.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(data[:,:,0], channel_axis=1, name=[\"ch0\", \"ch1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcdd2b",
   "metadata": {},
   "source": [
    "Add points and tracks to the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48047c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = tracks.loc[:, [\"frame\", \"y\", \"x\"]].to_numpy()\n",
    "viewer.add_points(points, size=0.5, symbol=\"disc\", face_color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf457f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_to_napari = tracks.loc[:, [\"particle\", \"frame\", \"y\", \"x\"]].to_numpy()\n",
    "viewer.add_tracks(tracks_to_napari, name=\"tracks\", tail_length=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging-python-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
